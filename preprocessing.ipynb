{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12f73a7",
   "metadata": {},
   "source": [
    "## Clean TechQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b234fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_paths = {\n",
    "    \"train\": {\n",
    "        \"qa\": \"/home/brachmat/phd/datasets/TechQA/training_and_dev/training_Q_A.json\",\n",
    "        \"doc\": \"/home/brachmat/phd/datasets/TechQA/training_and_dev/training_dev_technotes.json\"\n",
    "    },\n",
    "    \"dev\": {\n",
    "        \"qa\": \"/home/brachmat/phd/datasets/TechQA/training_and_dev/dev_Q_A.json\",\n",
    "        \"doc\": \"/home/brachmat/phd/datasets/TechQA/training_and_dev/training_dev_technotes.json\"\n",
    "    },\n",
    "    \"validation\": {\n",
    "        \"qa\": \"/home/brachmat/phd/datasets/TechQA/validation/validation_reference.json\",\n",
    "        \"doc\": \"/home/brachmat/phd/datasets/TechQA/validation/validation_technotes.json\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def safe_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except (TypeError, ValueError):\n",
    "        return -1\n",
    "\n",
    "def load_split(name, qa_path, doc_path):\n",
    "    with open(qa_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        qa_data = json.load(f)\n",
    "    with open(doc_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        doc_data = json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for q in qa_data:\n",
    "        question_id = q.get(\"QUESTION_ID\", \"\").strip()\n",
    "        question_text = q.get(\"QUESTION_TEXT\", \"\").strip()\n",
    "        answer_text = q.get(\"ANSWER\", \"\").strip()\n",
    "        passage_id = q.get(\"DOCUMENT\", \"\").strip()\n",
    "        passage_entry = doc_data.get(passage_id, {})\n",
    "\n",
    "        passage_title = passage_entry.get(\"title\", \"\").strip()\n",
    "        passage_text = passage_entry.get(\"text\") or passage_entry.get(\"content\", \"\")\n",
    "\n",
    "        start_offset = safe_int(q.get(\"START_OFFSET\"))\n",
    "        end_offset = safe_int(q.get(\"END_OFFSET\"))\n",
    "        answerable = int(q.get(\"ANSWERABLE\", \"\").strip().upper() == \"Y\")\n",
    "\n",
    "        records.append({\n",
    "            \"split\": name,\n",
    "            \"id\": question_id,\n",
    "            \"context\": passage_text,\n",
    "            \"title\": passage_title,\n",
    "            \"question\": question_text,\n",
    "            \"answer\": answer_text,\n",
    "            \"answer_start\": start_offset,\n",
    "            \"answer_end\": end_offset,\n",
    "            \"answerable\": answerable\n",
    "        })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "df = pd.concat(\n",
    "    [load_split(name, paths[\"qa\"], paths[\"doc\"]) for name, paths in qa_paths.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df = df[df['answer']!= \"\"]\n",
    "df = df[df['question']!= \"\"]\n",
    "\n",
    "# dev_df = df[df[\"split\"] == \"dev\"]\n",
    "\n",
    "# dev_train, dev_val = train_test_split(dev_df, test_size=0.3, random_state=42, stratify=dev_df[\"answerable\"])\n",
    "\n",
    "# dev_train = dev_train.copy()\n",
    "# dev_val = dev_val.copy()\n",
    "# dev_train[\"split\"] = \"train\"\n",
    "# dev_val[\"split\"] = \"validation\"\n",
    "\n",
    "# df = pd.concat([df[df[\"split\"] != \"dev\"], dev_train, dev_val], ignore_index=True)\n",
    "# df[\"split\"] = df[\"split\"].replace(\"dev\", \"validation\")\n",
    "\n",
    "df.to_csv(\"raw/techqa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563af02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data ---\n",
    "df_augmented = pd.read_csv(\"raw/augmented_techqa.csv\")\n",
    "ds = pd.read_csv(\"raw/techqa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f14582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_augmented: 5,048 rows\n",
      "df_filtered (in sampled ids): 5,021 rows\n",
      "dropped ERR rows: 5\n",
      "df_clean (only orig_id with exactly 9 rows): 4,986 rows\n",
      "unique orig_id in df_clean: 554\n"
     ]
    }
   ],
   "source": [
    "sampled_ids = set(ds[\"id\"])\n",
    "df_filtered = df_augmented[df_augmented[\"orig_id\"].isin(sampled_ids)]\n",
    "\n",
    "# --- Drop rows where aug_id contains 'ERR' (handle NaNs safely) ---\n",
    "mask_err = df_filtered[\"aug_id\"].astype(str).str.contains(\"ERR\", na=False)\n",
    "df_no_err = df_filtered[~mask_err]\n",
    "\n",
    "# --- Keep only orig_id that appear exactly 9 times ---\n",
    "counts = df_no_err[\"orig_id\"].value_counts()\n",
    "valid_ids = counts[counts == 9].index\n",
    "df_clean = df_no_err[df_no_err[\"orig_id\"].isin(valid_ids)].copy()\n",
    "\n",
    "assert (df_clean[\"orig_id\"].value_counts() == 9).all(), \"Some orig_id do not have exactly 9 rows.\"\n",
    "\n",
    "# --- Build mapping: orig_id -> original answer text from SQuAD v2 ---\n",
    "want_ids = set(df_clean[\"orig_id\"])\n",
    "\n",
    "id2answer = {}\n",
    "for _, ex in ds.iterrows():\n",
    "    qid = ex[\"id\"]\n",
    "    if qid in want_ids:\n",
    "        texts = ex[\"answer\"]\n",
    "        id2answer[qid] = texts if len(texts) > 0 else \"\"  # \"\" for unanswerable\n",
    "        if len(id2answer) == len(want_ids):\n",
    "            break\n",
    "\n",
    "df_clean[\"orig_answer\"] = df_clean[\"orig_id\"].map(id2answer)\n",
    "\n",
    "missing = df_clean[\"orig_answer\"].isna().sum()\n",
    "if missing:\n",
    "    print(f\"Warning: {missing} rows had no matching orig_answer in ds.\")\n",
    "\n",
    "df_clean['is_valid'] = None\n",
    "df_clean['reason'] = None\n",
    "df_clean['notes'] = None\n",
    "\n",
    "df_clean.to_csv(\"final/ds_techqa_aug.csv\", index=False)\n",
    "df_clean.iloc[0:216].to_csv(\"final/ds_techqa_aug_sample24.csv\", index=False)\n",
    "\n",
    "print(f\"df_augmented: {len(df_augmented):,} rows\")\n",
    "print(f\"df_filtered (in sampled ids): {len(df_filtered):,} rows\")\n",
    "print(f\"dropped ERR rows: {mask_err.sum():,}\")\n",
    "print(f\"df_clean (only orig_id with exactly 9 rows): {len(df_clean):,} rows\")\n",
    "print(f\"unique orig_id in df_clean: {df_clean['orig_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a749c",
   "metadata": {},
   "source": [
    "## Clean SQuADv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a9e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# --- Load data ---\n",
    "df_augmented = pd.read_csv(\"raw/augmented_squadv2.csv\")\n",
    "ds = load_dataset(\"/home/brachmat/phd/datasets/squad_v2\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb140af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_augmented: 820,401 rows\n",
      "df_filtered (in sampled ids): 5,396 rows\n",
      "dropped ERR rows: 2\n",
      "df_clean (only orig_id with exactly 9 rows): 5,382 rows\n",
      "unique orig_id in df_clean: 598\n"
     ]
    }
   ],
   "source": [
    "# --- Take first 91k, then sample 6k ---\n",
    "ds_sampled = ds.select(range(91_000)).shuffle(seed=42).select(range(600))\n",
    "\n",
    "# --- Filter augmented rows to only those with orig_id in sampled ids ---\n",
    "sampled_ids = set(ds_sampled[\"id\"])\n",
    "df_filtered = df_augmented[df_augmented[\"orig_id\"].isin(sampled_ids)]\n",
    "\n",
    "# --- Drop rows where aug_id contains 'ERR' (handle NaNs safely) ---\n",
    "mask_err = df_filtered[\"aug_id\"].astype(str).str.contains(\"ERR\", na=False)\n",
    "df_no_err = df_filtered[~mask_err]\n",
    "\n",
    "# --- Keep only orig_id that appear exactly 9 times ---\n",
    "counts = df_no_err[\"orig_id\"].value_counts()\n",
    "valid_ids = counts[counts == 9].index\n",
    "df_clean = df_no_err[df_no_err[\"orig_id\"].isin(valid_ids)].copy()\n",
    "\n",
    "assert (df_clean[\"orig_id\"].value_counts() == 9).all(), \"Some orig_id do not have exactly 9 rows.\"\n",
    "\n",
    "# --- Build mapping: orig_id -> original answer text from SQuAD v2 ---\n",
    "want_ids = set(df_clean[\"orig_id\"])\n",
    "\n",
    "id2answer = {}\n",
    "for ex in ds:\n",
    "    qid = ex[\"id\"]\n",
    "    if qid in want_ids:\n",
    "        texts = ex[\"answers\"][\"text\"]\n",
    "        id2answer[qid] = texts[0] if len(texts) > 0 else \"\"  # \"\" for unanswerable\n",
    "        if len(id2answer) == len(want_ids):\n",
    "            break\n",
    "\n",
    "df_clean[\"orig_answer\"] = df_clean[\"orig_id\"].map(id2answer)\n",
    "\n",
    "missing = df_clean[\"orig_answer\"].isna().sum()\n",
    "if missing:\n",
    "    print(f\"Warning: {missing} rows had no matching orig_answer in ds.\")\n",
    "\n",
    "df_clean['is_valid'] = None\n",
    "df_clean['reason'] = None\n",
    "df_clean['notes'] = None\n",
    "\n",
    "\n",
    "df_clean.to_csv(\"final/ds_squadv2_aug.csv\", index=False)\n",
    "ds_sampled.to_pandas().to_csv(\"final/ds_squadv2.csv\", index=False)\n",
    "df_clean.iloc[0:216].to_csv(\"final/ds_squadv2_aug_sample24.csv\", index=False)\n",
    "\n",
    "print(f\"df_augmented: {len(df_augmented):,} rows\")\n",
    "print(f\"df_filtered (in sampled ids): {len(df_filtered):,} rows\")\n",
    "print(f\"dropped ERR rows: {mask_err.sum():,}\")\n",
    "print(f\"df_clean (only orig_id with exactly 9 rows): {len(df_clean):,} rows\")\n",
    "print(f\"unique orig_id in df_clean: {df_clean['orig_id'].nunique():,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
